{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "from teeplot import teeplot as tp\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_parquet(slug: str) -> pl.LazyFrame:\n",
    "    response = requests.get(f\"https://osf.io/{slug}/download\", stream=True)\n",
    "\n",
    "    total_size = int(response.headers.get(\"content-length\", 0))\n",
    "    block_size = 1024\n",
    "\n",
    "    with tqdm(total=total_size, unit=\"B\", unit_scale=True) as progress_bar:\n",
    "        with open(f\"/tmp/{slug}\", \"wb\") as file:\n",
    "            for data in response.iter_content(block_size):\n",
    "                progress_bar.update(len(data))\n",
    "                file.write(data)\n",
    "\n",
    "    return pl.scan_parquet(f\"/tmp/{slug}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df1 = scan_parquet(\n",
    "        \"musp8\",\n",
    "    ).with_columns(\n",
    "        pl.lit(\"baseline\").alias(\"what\"),\n",
    "    ).filter(\n",
    "        pl.col(\"Treatment\") == \"Slip-duplicate\",\n",
    "    ).collect()\n",
    "    len(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df2 = scan_parquet(\n",
    "        \"72d6m\",\n",
    "    ).filter(\n",
    "        pl.col(\"Treatment\") == \"Slip-duplicate\",\n",
    "    ).with_columns(\n",
    "        pl.lit(\"insertions\").alias(\"what\"),\n",
    "    ).collect()\n",
    "    len(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df3 = scan_parquet(\n",
    "        \"sudfh\",\n",
    "    ).filter(\n",
    "        pl.col(\"Treatment\") == \"Slip-duplicate\",\n",
    "    ).with_columns(\n",
    "        pl.lit(\"deletions\").alias(\"what\"),\n",
    "    ).collect()\n",
    "    len(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = pl.concat(\n",
    "        [df1.lazy(), df2.lazy(), df3.lazy()],\n",
    "        how=\"vertical_relaxed\",\n",
    "    ).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        Components=pl.col(\"Task\").replace_strict(\n",
    "            {\n",
    "                \"AND\": 2,\n",
    "                \"ANDNOT\": 3,\n",
    "                \"NAND\": 1,\n",
    "                \"NOR\": 4,\n",
    "                \"NOT\": 1,\n",
    "                \"OR\": 3,\n",
    "                \"ORNOT\": 2,\n",
    "                \"XOR\": 4,\n",
    "                \"EQUALS\": 5,\n",
    "            },\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        (\n",
    "            pl.col(\"Components\")\n",
    "            * pl.col(\"Has Task\")\n",
    "        ).max().over(\n",
    "            [\"Treatment\", \"Run ID\", \"Generation Born\"],\n",
    "        ).alias(\"max components\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        TaskNumber=pl.col(\"Task\").replace_strict(\n",
    "            dict(map(reversed, enumerate(df[\"Task\"].unique()))),\n",
    "        ),\n",
    "    ).with_columns(\n",
    "        TaskBit=np.left_shift(1, pl.col(\"TaskNumber\")),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        SetTaskBit=pl.col(\"TaskBit\") * pl.col(\"Has Task\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"SetTaskBit\").bitwise_or().over(\n",
    "            [\"Treatment\", \"Run ID\", \"Generation Born\", \"what\"],\n",
    "        )\n",
    "        .alias(\"SetTaskBits\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"Is Task Coding Site\").any().over(\n",
    "            [\"Treatment\", \"Run ID\", \"Generation Born\", \"Site\", \"what\"],\n",
    "        )\n",
    "        .alias(\"is any coding site\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"Has Task\").sum().over(\n",
    "            [\"Treatment\", \"Run ID\", \"Generation Born\", \"Site\", \"what\"],\n",
    "        )\n",
    "        .alias(\"num tasks has\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    assert df.lazy().group_by(\n",
    "        [\"Treatment\", \"Run ID\", \"Generation Born\", \"what\"]\n",
    "    ).agg(\n",
    "        pl.col(\"num tasks has\").n_unique(),\n",
    "    ).select(\"num tasks has\").max().collect().item() == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    df = df.with_columns(\n",
    "        pl.col(\"is any coding site\").sum().over(\n",
    "            [\"Treatment\", \"Run ID\", \"Generation Born\", \"Task\", \"what\"],\n",
    "        ).alias(\"num coding sites\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"CI\" not in os.environ:\n",
    "    dfx = df.group_by(\n",
    "        [\"Treatment\", \"Run ID\", \"Generation Born\", \"what\"],\n",
    "    ).first()\n",
    "else:\n",
    "    dfx = scan_parquet(\"8xt2p\").collect()\n",
    "dfx.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfx.write_parquet(\"/tmp/indel-effect-nulldist.pqt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_ = dfx.filter(pl.col(\"what\") == \"baseline\").sort(\n",
    "    \"Treatment\", \"Run ID\", \"Generation Born\"\n",
    ")\n",
    "df2_ = dfx.filter(pl.col(\"what\") == \"insertions\").sort(\n",
    "    \"Treatment\", \"Run ID\", \"Generation Born\"\n",
    ")\n",
    "df3_ = dfx.filter(pl.col(\"what\") == \"deletions\").sort(\n",
    "    \"Treatment\", \"Run ID\", \"Generation Born\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_ncs_insertion = (\n",
    "    df2_[\"num coding sites\"].to_numpy().astype(np.int64)\n",
    "    - df1_[\"num coding sites\"].to_numpy().astype(np.int64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_ncs_deletion = (\n",
    "    df3_[\"num coding sites\"].to_numpy().astype(np.int64)\n",
    "    - df1_[\"num coding sites\"].to_numpy().astype(np.int64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_nth_insertion = (\n",
    "    df2_[\"num tasks has\"].to_numpy().astype(np.int64)\n",
    "    - df1_[\"num tasks has\"].to_numpy().astype(np.int64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_nth_deletion = (\n",
    "    df3_[\"num tasks has\"].to_numpy().astype(np.int64)\n",
    "    - df1_[\"num tasks has\"].to_numpy().astype(np.int64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_tasks_insertion = (\n",
    "    df2_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    "    != df1_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_tasks_deletion = (\n",
    "    df3_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    "    != df1_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gained_task_insertion = (\n",
    "    df2_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    "    & np.invert(df1_[\"SetTaskBits\"].to_numpy().astype(np.int64))\n",
    ").astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gained_task_deletion = (\n",
    "    df3_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    "    & np.invert(df1_[\"SetTaskBits\"].to_numpy().astype(np.int64))\n",
    ").astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_task_insertion = (\n",
    "    np.invert(df2_[\"SetTaskBits\"].to_numpy().astype(np.int64))\n",
    "    & df1_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    ").astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_task_deletion = (\n",
    "    np.invert(df3_[\"SetTaskBits\"].to_numpy().astype(np.int64))\n",
    "    & df1_[\"SetTaskBits\"].to_numpy().astype(np.int64)\n",
    ").astype(bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_effect_lookup = {\n",
    "    -1: \"deleterious\",\n",
    "    0: \"neutral\",\n",
    "    1: \"beneficial\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_effect_insertion = np.vectorize(fitness_effect_lookup.__getitem__)(\n",
    "    np.sign(2 * gained_task_insertion - lost_task_insertion),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_effect_deletion = np.vectorize(fitness_effect_lookup.__getitem__)(\n",
    "    np.sign(2 * gained_task_insertion - lost_task_insertion),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz = pl.concat(\n",
    "    [\n",
    "        pl.DataFrame(\n",
    "            {\n",
    "                \"Treatment\": df1_[\"Treatment\"],\n",
    "                \"Run ID\": df1_[\"Run ID\"],\n",
    "                \"Generation Born\": df1_[\"Generation Born\"],\n",
    "                \"what\": \"insertion\",\n",
    "                \"delta num coding sites\": delta_ncs_insertion,\n",
    "                \"delta num tasks has\": delta_nth_insertion,\n",
    "                \"num tasks has\": df1_[\"num tasks has\"],\n",
    "                \"num coding sites\": df1_[\"num coding sites\"],\n",
    "                \"delta tasks\": delta_tasks_insertion,\n",
    "                \"gained task\": gained_task_insertion,\n",
    "                \"lost task\": gained_task_insertion,\n",
    "                \"max components\": df1_[\"max components\"],\n",
    "                \"fitness effect\": fitness_effect_insertion,\n",
    "            },\n",
    "        ),\n",
    "        # disable deletion outputs, as they are not of interest\n",
    "        # pl.DataFrame(\n",
    "        #     {\n",
    "        #         \"Treatment\": df1_[\"Treatment\"],\n",
    "        #         \"Run ID\": df1_[\"Run ID\"],\n",
    "        #         \"Generation Born\": df1_[\"Generation Born\"],\n",
    "        #         \"what\": \"deletion\",\n",
    "        #         \"delta num coding sites\": delta_ncs_deletion,\n",
    "        #         \"delta num tasks has\": delta_nth_deletion,\n",
    "        #         \"num tasks has\": df1_[\"num tasks has\"],\n",
    "        #         \"num coding sites\": df1_[\"num coding sites\"],\n",
    "        #         \"delta tasks\": delta_tasks_deletion,\n",
    "        #         \"gained task\": gained_task_deletion,\n",
    "        #         \"lost task\": lost_task_deletion,\n",
    "        #         \"max components\": df1_[\"max components\"],\n",
    "        #         \"fitness effect\": fitness_effect_deletion,\n",
    "        #     },\n",
    "        # ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "dfz = dfz.with_columns(\n",
    "    (\n",
    "        dfz[\"delta num coding sites\"] / (\n",
    "            dfz[\"num coding sites\"]\n",
    "        )\n",
    "    ).alias(\"delta frac coding sites\")\n",
    ")\n",
    "dfz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfz.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for kind in \"bar\", \"violin\":\n",
    "    saveit, g = tp.tee(\n",
    "        sns.catplot,\n",
    "        data=dfz.to_pandas(),\n",
    "        col=\"what\",\n",
    "        y=\"delta num coding sites\",\n",
    "        kind=kind,\n",
    "        teeplot_callback=True,\n",
    "    )\n",
    "    for ax in g.axes.flat:\n",
    "        ax.axhline(0, color=\"black\", linewidth=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in \"fitness effect\", \"max components\", \"num tasks has\":\n",
    "    for kind in \"bar\", \"violin\":\n",
    "        saveit, g = tp.tee(\n",
    "            sns.catplot,\n",
    "            data=dfz.to_pandas(),\n",
    "            col=\"what\",\n",
    "            x=x,\n",
    "            y=\"delta num coding sites\",\n",
    "            hue=\"fitness effect\",\n",
    "            hue_order=[\"deleterious\", \"neutral\", \"beneficial\"],\n",
    "            kind=kind,\n",
    "            palette=\"pastel\",\n",
    "            teeplot_callback=True,\n",
    "            aspect=0.9,\n",
    "            height=3,\n",
    "        )\n",
    "        if x != \"max components\":\n",
    "            g.set(xticklabels=[], xlabel=\"\")\n",
    "        else:\n",
    "            g.set(xlabel=\"max task complexity\")\n",
    "        g.set_titles(\"\")\n",
    "        for ax in g.axes.flat:\n",
    "            xs = [line.get_xdata().min() for line in ax.lines]\n",
    "            lower = [line.get_ydata().min() for line in ax.lines]\n",
    "            upper = [line.get_ydata().max() for line in ax.lines]\n",
    "            cis = [*zip(lower, upper)]\n",
    "            order = np.argsort(xs)\n",
    "            for o in order:\n",
    "                print(cis[o])\n",
    "            ax.axhline(0, color=\"black\", linewidth=1)\n",
    "        saveit()\n",
    "\n",
    "    for kind in \"bar\", \"violin\":\n",
    "        saveit, g = tp.tee(\n",
    "            sns.catplot,\n",
    "            data=dfz.to_pandas(),\n",
    "            col=\"what\",\n",
    "            x=x,\n",
    "            y=\"delta num coding sites\",\n",
    "            hue=\"fitness effect\",\n",
    "            hue_order=[\"deleterious\", \"neutral\", \"beneficial\"],\n",
    "            kind=kind,\n",
    "            palette=\"pastel\",\n",
    "            teeplot_callback=True,\n",
    "            teeplot_outattrs={\"textlabels\": True},\n",
    "            aspect=0.9,\n",
    "            height=3,\n",
    "        )\n",
    "        if x != \"max components\":\n",
    "            g.set(xticklabels=[], xlabel=\"\")\n",
    "        else:\n",
    "            g.set(xlabel=\"max task complexity\")\n",
    "        g.set_titles(\"\")\n",
    "        for ax in g.axes.flat:\n",
    "            xs = [line.get_xdata().min() for line in ax.lines]\n",
    "            lower = [line.get_ydata().min() for line in ax.lines]\n",
    "            upper = [line.get_ydata().max() for line in ax.lines]\n",
    "            cis = [*zip(lower, upper)]\n",
    "            order = np.argsort(xs)\n",
    "            for o in order:\n",
    "                print(cis[o])\n",
    "            ax.axhline(0, color=\"black\", linewidth=1)\n",
    "            # add count labels\n",
    "            # adapted from https://stackoverflow.com/a/55319634/17332200\n",
    "            for p in ax.patches:\n",
    "                ax.annotate(\n",
    "                    text=f\"{p.get_height():1.1f}\",\n",
    "                    xy=(\n",
    "                        p.get_x() + p.get_width() / 2.,\n",
    "                        -5 * np.sign(p.get_height())\n",
    "                    ),\n",
    "                    xycoords=\"data\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontsize=11,\n",
    "                    color=\"black\",\n",
    "                    xytext=(0,0),\n",
    "                    textcoords=\"offset points\",\n",
    "                    clip_on=True,                   # <---  important\n",
    "                )\n",
    "        saveit()\n",
    "\n",
    "    saveit, g = tp.tee(\n",
    "        sns.displot,\n",
    "        data=dfz.to_pandas(),\n",
    "        col=\"what\",\n",
    "        x=x,\n",
    "        kind=\"hist\",\n",
    "        hue=\"fitness effect\",\n",
    "        hue_order=[\"deleterious\", \"neutral\", \"beneficial\"],\n",
    "        multiple=\"stack\" if x == \"fitness effect\" else \"dodge\",\n",
    "        palette=\"pastel\",\n",
    "        stat=\"probability\",\n",
    "        teeplot_callback=True,\n",
    "        aspect=0.9,\n",
    "        height=3,\n",
    "    )\n",
    "    plt.yscale(\"symlog\", linthresh=5e-2)\n",
    "    g.set(xticklabels=[], xlabel=\"\", ylim=(0, 1.5))\n",
    "    g.set_titles(\"\")\n",
    "\n",
    "    # add count labels\n",
    "    # adapted from https://stackoverflow.com/a/55319634/17332200\n",
    "    for ax in g.axes.flat:\n",
    "        xs = [line.get_xdata().min() for line in ax.lines]\n",
    "        lower = [line.get_ydata().min() for line in ax.lines]\n",
    "        upper = [line.get_ydata().max() for line in ax.lines]\n",
    "        cis = [*zip(lower, upper)]\n",
    "        order = np.argsort(xs)\n",
    "        for o in order:\n",
    "            print(cis[o])\n",
    "\n",
    "        for p in ax.patches:\n",
    "            if p.get_height() > 0.0001:\n",
    "                ax.annotate(\n",
    "                    text=f\"{p.get_height():1.3f}\",\n",
    "                    xy=(\n",
    "                        p.get_x() + p.get_width() / 2.,\n",
    "                        p.get_height(),\n",
    "                    ),\n",
    "                    xycoords=\"data\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontsize=11,\n",
    "                    color=\"black\",\n",
    "                    xytext=(0,7),\n",
    "                    textcoords=\"offset points\",\n",
    "                    clip_on=True,                   # <---  important\n",
    "                )\n",
    "\n",
    "    saveit()\n",
    "\n",
    "    saveit, g = tp.tee(\n",
    "        sns.displot,\n",
    "        data=dfz.to_pandas(),\n",
    "        col=\"what\",\n",
    "        x=x,\n",
    "        kind=\"hist\",\n",
    "        hue=\"fitness effect\",\n",
    "        hue_order=[\"deleterious\", \"neutral\", \"beneficial\"],\n",
    "        stat=\"count\",\n",
    "        palette=\"pastel\",\n",
    "        multiple=\"stack\" if x == \"fitness effect\" else \"dodge\",\n",
    "        teeplot_callback=True,\n",
    "        aspect=0.9,\n",
    "        height=3,\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    if x != \"max components\":\n",
    "        g.set(xticklabels=[], xlabel=\"\")\n",
    "    else:\n",
    "        g.set(xlabel=\"max task complexity\")\n",
    "    g.set_titles(\"\")\n",
    "\n",
    "    # add count labels\n",
    "    # adapted from https://stackoverflow.com/a/55319634/17332200\n",
    "    for ax in g.axes.flat:\n",
    "        xs = [line.get_xdata().min() for line in ax.lines]\n",
    "        lower = [line.get_ydata().min() for line in ax.lines]\n",
    "        upper = [line.get_ydata().max() for line in ax.lines]\n",
    "        cis = [*zip(lower, upper)]\n",
    "        order = np.argsort(xs)\n",
    "        for o in order:\n",
    "            print(cis[o])\n",
    "\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(\n",
    "                text=f\"{p.get_height():1.0f}\",\n",
    "                xy=(\n",
    "                    p.get_x() + p.get_width() / 2.,\n",
    "                    -5 * np.sign(p.get_height()),\n",
    "                ),\n",
    "                xycoords=\"data\",\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                fontsize=11,\n",
    "                color=\"black\",\n",
    "                xytext=(0,0),\n",
    "                textcoords=\"offset points\",\n",
    "                clip_on=True,                   # <---  important\n",
    "            )\n",
    "\n",
    "    saveit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in \"fitness effect\", \"max components\", \"num tasks has\":\n",
    "    display(\n",
    "        dfz.to_pandas().groupby(\n",
    "            [\"what\", x, \"fitness effect\"],\n",
    "        ).agg(\n",
    "            {\n",
    "                \"delta frac coding sites\": [\"median\", \"mean\", \"std\", \"count\"],\n",
    "            },\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp.tee(\n",
    "    sns.displot,\n",
    "    data=dfz.to_pandas(),\n",
    "    x=\"delta num coding sites\",\n",
    "    y=\"delta num tasks has\",\n",
    "    row=\"what\",\n",
    "    common_norm=False,\n",
    "    col=\"num tasks has\",\n",
    "    kind=\"hist\",\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
